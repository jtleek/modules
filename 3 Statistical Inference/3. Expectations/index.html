<!DOCTYPE html>
<html>
<head>
  <title>Expectations</title>
  <meta charset="utf-8">
  <meta name="description" content="Expectations">
  <meta name="author" content="Brian Caffo, PhD">
  <meta name="generator" content="slidify" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <link rel="stylesheet" href="../../libraries/frameworks/io2012/css/default.css" media="all" >
  <link rel="stylesheet" href="../../libraries/frameworks/io2012/phone.css" 
    media="only screen and (max-device-width: 480px)" >
  <link rel="stylesheet" href="../../libraries/frameworks/io2012/css/slidify.css" >
  <link rel="stylesheet" href="../../libraries/highlighters/highlight.js/css/tomorrow.css" />
  <base target="_blank"> <!-- This amazingness opens all links in a new tab. -->
  <script data-main="../../libraries/frameworks/io2012/js/slides" 
    src="../../libraries/frameworks/io2012/js/require-1.0.8.min.js">
  </script>
  
    <link rel="stylesheet" href = "../../assets/css/custom.css">
<link rel="stylesheet" href = "../../assets/css/ribbons.css">

</head>
<body style="opacity: 0">
  <slides class="layout-widescreen">
    
    <!-- LOGO SLIDE -->
    <!-- END LOGO SLIDE -->
    

    <!-- TITLE SLIDE -->
    <!-- Should I move this to a Local Layout File? -->
    <slide class="title-slide segue nobackground">
      <aside class="gdbar">
        <img src="../../assets/img/bloomberg_shield.png">
      </aside>
      <hgroup class="auto-fadein">
        <h1>Expectations</h1>
        <h2>Mathematical Biostatistics Boot Camp</h2>
        <p>Brian Caffo, PhD<br/>Johns Hopkins Bloomberg School of Public Health</p>
      </hgroup>
          </slide>

    <!-- SLIDES -->
      <slide class="" id="slide-1" style="background:;">
  <hgroup>
    <h2>Table of contents</h2>
  </hgroup>
  <article>
    <ol>
<li>Expected values

<ul>
<li>Discrete random variables</li>
<li>Continuous random variables</li>
</ul></li>
<li>Rules about expected values</li>
<li>Variances</li>
<li>Chebyshevâ€™s inequality</li>
</ol>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-2" style="background:;">
  <hgroup>
    <h2>Expected values</h2>
  </hgroup>
  <article>
    <ul>
<li>The {\bf expected value} or {\bf mean} of a random variable is the center of its distribution</li>
<li>For discrete random variable \(X\) with PMF \(p(x)\), it is defined as follows
\[
E[X] = \sum_x xp(x).
\]
where the sum is taken over the possible values of \(x\)</li>
<li>\(E[X]\) represents the center of mass of a collection of locations and weights, \(\{x, p(x)\}\)</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-3" style="background:;">
  <hgroup>
    <h2>Example</h2>
  </hgroup>
  <article>
    <p><img src="../assets/mean.png" height=400></p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-4" style="background:;">
  <hgroup>
    <h2>Example</h2>
  </hgroup>
  <article>
    <ul>
<li>Suppose a coin is flipped and \(X\) is declared \(0\) or \(1\) corresponding to a head or a tail, respectively</li>
<li>What is the expected value of \(X\)? 
\[
E[X] = .5 \times 0 + .5 \times 1 = .5
\]</li>
<li>Note, if thought about geometrically, this answer is obvious; if two equal weights are spaced at 0 and 1, the center of mass will be \(.5\)</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-5" style="background:;">
  <hgroup>
    <h2>Example</h2>
  </hgroup>
  <article>
    <ul>
<li>Suppose that a die is rolled and \(X\) is the number face up</li>
<li>What is the expected value of \(X\)?
\[
E[X] = 1 \times \frac{1}{6} + 2 \times \frac{1}{6} +
3 \times \frac{1}{6} + 4 \times \frac{1}{6} +
5 \times \frac{1}{6} + 6 \times \frac{1}{6} = 3.5
\]</li>
<li>Again, the geometric argument makes this answer obvious without calculation.</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-6" style="background:;">
  <hgroup>
    <h2>Continuous random variables</h2>
  </hgroup>
  <article>
    <ul>
<li>For a continuous random variable, \(X\), with density, \(f\), the expected
value is defined as follows
\[
E[X] = \int_{-\infty}^\infty t f(t)dt
\]</li>
<li>This definition borrows from the definition of center of mass for a continuous body</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-7" style="background:;">
  <hgroup>
    <h2>Example</h2>
  </hgroup>
  <article>
    <ul>
<li>Consider a density where \(f(x) = 1\) for \(x\) between zero and one</li>
<li>(Is this a valid density?)</li>
<li>Suppose that \(X\) follows this density; what is its expected value? 
\[
E[X] = \int_{0}^{1} x dx = \left. \frac{x^2}{2} ~\right|_{0}^{1} = 1/2
\]</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-8" style="background:;">
  <hgroup>
    <h2>Rules about expected values</h2>
  </hgroup>
  <article>
    <ul>
<li>The expected value is a linear operator </li>
<li><p>If \(a\) and \(b\) are not random and \(X\) and \(Y\) are two random variables then</p>

<ul>
<li>\(E[aX + b] = a E[X] + b\)</li>
<li>\(E[X + Y] = E[X] + E[Y]\)</li>
</ul></li>
<li><p><em>In general</em> if \(g\) is a function that is not linear,
\[
E[g(X)] \neq g(E[X])
\]</p></li>
<li><p>For example, in general, \(E[X^2] \neq E[X]^2\) </p></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-9" style="background:;">
  <hgroup>
    <h2>Example</h2>
  </hgroup>
  <article>
    <ul>
<li>You flip a coin, \(X\) and simulate a uniform random number \(Y\), what is the expected value of their sum? 
\[
E[X + Y] = E[X] + E[Y] = .5 + .5 = 1
\] </li>
<li>Another example, you roll a die twice. What is the expected value of the average? </li>
<li>Let \(X_1\) and \(X_2\) be the results of the two rolls
\[
E[(X_1 + X_2) / 2] = \frac{1}{2}(E[X_1] + E[X_2])
= \frac{1}{2}(3.5 + 3.5) = 3.5
\]</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-10" style="background:;">
  <hgroup>
    <h2>Example</h2>
  </hgroup>
  <article>
    <ol>
<li>Let \(X_i\) for \(i=1,\ldots,n\) be a collection of random variables, each from a distribution with mean \(\mu\)</li>
<li>Calculate the expected value of the sample average of the \(X_i\)
\[
\begin{eqnarray*}
E\left[ \frac{1}{n}\sum_{i=1}^n X_i\right]
& = & \frac{1}{n} E\left[\sum_{i=1}^n X_i\right] \\
& = & \frac{1}{n} \sum_{i=1}^n E\left[X_i\right] \\
& = & \frac{1}{n} \sum_{i=1}^n \mu =  \mu.
\end{eqnarray*}
\]</li>
</ol>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-11" style="background:;">
  <hgroup>
    <h2>Remark</h2>
  </hgroup>
  <article>
    <ul>
<li>Therefore, the expected value of the <strong>sample mean</strong> is the population mean that it&#39;s trying to estimate</li>
<li>When the expected value of an estimator is what its trying to estimate, we say that the estimator is <strong>unbiased</strong></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-12" style="background:;">
  <hgroup>
    <h2>The variance</h2>
  </hgroup>
  <article>
    <ul>
<li>The variance of a random variable is a measure of {\em spread}</li>
<li>If \(X\) is a random variable with mean \(\mu\), the variance of \(X\) is defined as</li>
</ul>

<p>\[
Var(X) = E[(X - \mu)^2]
\]</p>

<p>the expected (squared) distance from the mean</p>

<ul>
<li>Densities with a higher variance are more spread out than densities with a lower variance</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-13" style="background:;">
  <hgroup>
    
  </hgroup>
  <article>
    <ul>
<li>Convenient computational form
\[
Var(X) = E[X^2] - E[X]^2
\]</li>
<li>If \(a\) is constant then \(Var(aX) = a^2 Var(X)\)</li>
<li>The square root of the variance is called the <strong>standard deviation</strong></li>
<li>The standard deviation has the same units as \(X\)</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-14" style="background:;">
  <hgroup>
    <h2>Example</h2>
  </hgroup>
  <article>
    <ul>
<li><p>What&#39;s the sample variance from the result of a toss of a die? </p>

<ul>
<li>\(E[X] = 3.5\) </li>
<li>\(E[X^2] = 1 ^ 2 \times \frac{1}{6} + 2 ^ 2 \times \frac{1}{6} + 3 ^ 2 \times \frac{1}{6} + 4 ^ 2 \times \frac{1}{6} + 5 ^ 2 \times \frac{1}{6} + 6 ^ 2 \times \frac{1}{6} = 15.17\) </li>
</ul></li>
<li><p>\(Var(X) = E[X^2] - E[X]^2 \approx 2.92\)</p></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-15" style="background:;">
  <hgroup>
    <h2>Example</h2>
  </hgroup>
  <article>
    <ul>
<li><p>What&#39;s the sample variance from the result of the toss of a coin with probability of heads (1) of \(p\)? </p>

<ul>
<li>\(E[X] = 0 \times (1 - p) + 1 \times p = p\)</li>
<li>\(E[X^2] = E[X] = p\) </li>
</ul></li>
<li><p>\(Var(X) = E[X^2] - E[X]^2 = p - p^2 = p(1 - p)\)</p></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-16" style="background:;">
  <hgroup>
    <h2>Example</h2>
  </hgroup>
  <article>
    <ul>
<li>Suppose that a random variable is such that \(0 \leq X \leq 1\) and \(E[X] = p\)</li>
<li>Note \(X^2 \leq X\) so that \(E[X^2] \leq E[X] = p\)</li>
<li>\(Var(X) = E[X^2] - E[X]^2 \leq E[X] - E[X]^2 = p(1-p)\)</li>
<li>Therefore the Bernoulli variance is the largest possible for random variables bounded between \(0\) and \(1\)</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-17" style="background:;">
  <hgroup>
    <h2>Interpreting variances</h2>
  </hgroup>
  <article>
    <ul>
<li>Chebyshev&#39;s inequality is useful for interpreting variances</li>
<li>This inequality states that
\[
P(|X - \mu| \geq k\sigma) \leq \frac{1}{k^2}
\]</li>
<li>For example, the probability that a random variable lies beyond \(k\) standard deviations from its mean is less than \(1/k^2\)
\[
\begin{eqnarray*}
2\sigma & \rightarrow & 25\% \\
3\sigma & \rightarrow & 11\% \\
4\sigma & \rightarrow &  6\% 
\end{eqnarray*}
\]</li>
<li>Note this is only a bound; the actual probability might be quite a bit smaller</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-18" style="background:;">
  <hgroup>
    <h2>Proof of Chebyshev&#39;s inequality</h2>
  </hgroup>
  <article>
    <p>\[
\begin{eqnarray*}
    P(|X - \mu| > k\sigma) & = & \int_{\{x: |x-\mu| > k\sigma\}} f(x) dx \\
& \leq & \int_{\{x:|x -\mu| > k\sigma\}}\frac{(x - \mu)^2}{k^2\sigma^2} f(x) dx \\
& \leq & \int_{-\infty}^{\infty} \frac{(x - \mu)^2}{k^2\sigma^2} f(x) dx \\
& = & \frac{1}{k^2}
  \end{eqnarray*}
\]</p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-19" style="background:;">
  <hgroup>
    <h2>Example</h2>
  </hgroup>
  <article>
    <ul>
<li>IQs are often said to be distributed with a mean of \(100\) and a sd of \(15\)</li>
<li>What is the probability of a randomly drawn person having an IQ higher than \(160\) or below \(40\)?</li>
<li>Thus we want to know the probability of a person being more than \(4\) standard deviations from the mean</li>
<li>Thus Chebyshev&#39;s inequality suggests that this will be no larger than 6\%</li>
<li>IQs distributions are often cited as being bell shaped, in which case this bound is very conservative</li>
<li>The probability of a random draw from a bell curve being \(4\) standard deviations from the mean is on the order of \(10^{-5}\) (one thousandth of one percent)</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-20" style="background:;">
  <hgroup>
    <h2>Example</h2>
  </hgroup>
  <article>
    <ul>
<li>A popular buzz phrase in industrial quality control is Motorola&#39;s``Six Sigma&#39;&#39; whereby businesses are suggested to control extreme events or rare defective parts</li>
<li>Chebyshev&#39;s inequality states that the probability of a ``Six Sigma&#39;&#39; event is less than \(1/6^2 \approx 3\%\)</li>
<li>If a bell curve is assumed, the probability of a ``six sigma&#39;&#39; event is on the order of \(10^{-9}\) (one ten millionth of a percent)</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

    <slide class="backdrop"></slide>
  </slides>

  <!--[if IE]>
    <script 
      src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js">  
    </script>
    <script>CFInstall.check({mode: 'overlay'});</script>
  <![endif]-->
</body>
<!-- Grab CDN jQuery, fall back to local if offline -->
<script src="http://ajax.aspnetcdn.com/ajax/jQuery/jquery-1.7.min.js"></script>
<script>window.jQuery || document.write('<script src="../../libraries/widgets/quiz/js/jquery-1.7.min.js"><\/script>')</script>
<!-- Load Javascripts for Widgets -->
<!-- MathJax: Fall back to local if CDN offline but local image fonts are not supported (saves >100MB) -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<!-- <script src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script> -->
<script>window.MathJax || document.write('<script type="text/x-mathjax-config">MathJax.Hub.Config({"HTML-CSS":{imageFont:null}});<\/script><script src="../../libraries/widgets/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"><\/script>')
</script>
<!-- LOAD HIGHLIGHTER JS FILES -->
<script src="../../libraries/highlighters/highlight.js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<!-- DONE LOADING HIGHLIGHTER JS FILES -->
</html>