<!DOCTYPE html>
<html>
<head>
  <title>Independence</title>
  <meta charset="utf-8">
  <meta name="description" content="Independence">
  <meta name="author" content="Brian Caffo, Jeff Leek, Roger Peng">
  <meta name="generator" content="slidify" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <link rel="stylesheet" href="../../libraries/frameworks/io2012/css/default.css" media="all" >
  <link rel="stylesheet" href="../../libraries/frameworks/io2012/phone.css" 
    media="only screen and (max-device-width: 480px)" >
  <link rel="stylesheet" href="../../libraries/frameworks/io2012/css/slidify.css" >
  <link rel="stylesheet" href="../../libraries/highlighters/highlight.js/css/tomorrow.css" />
  <base target="_blank"> <!-- This amazingness opens all links in a new tab. -->
  <script data-main="../../libraries/frameworks/io2012/js/slides" 
    src="../../libraries/frameworks/io2012/js/require-1.0.8.min.js">
  </script>
  
    <link rel="stylesheet" href = "../../assets/css/custom.css">
<link rel="stylesheet" href = "../../assets/css/custom.css.BACKUP.546.css">
<link rel="stylesheet" href = "../../assets/css/custom.css.BASE.546.css">
<link rel="stylesheet" href = "../../assets/css/custom.css.LOCAL.546.css">
<link rel="stylesheet" href = "../../assets/css/custom.css.orig">
<link rel="stylesheet" href = "../../assets/css/custom.css.REMOTE.546.css">
<link rel="stylesheet" href = "../../assets/css/ribbons.css">

</head>
<body style="opacity: 0">
  <slides class="layout-widescreen">
    
    <!-- LOGO SLIDE -->
    <!-- END LOGO SLIDE -->
    

    <!-- TITLE SLIDE -->
    <!-- Should I move this to a Local Layout File? -->
    <slide class="title-slide segue nobackground">
      <aside class="gdbar">
        <img src="../../assets/img/bloomberg_shield.png">
      </aside>
      <hgroup class="auto-fadein">
        <h1>Independence</h1>
        <h2>Statistical Inference</h2>
        <p>Brian Caffo, Jeff Leek, Roger Peng<br/>Johns Hopkins Bloomberg School of Public Health</p>
      </hgroup>
          </slide>

    <!-- SLIDES -->
      <slide class="" id="slide-1" style="background:;">
  <hgroup>
    <h2>Independent events</h2>
  </hgroup>
  <article>
    <ul>
<li>Two events \(A\) and \(B\) are <strong>independent</strong> if \[P(A \cap B) = P(A)P(B)\]</li>
<li>Two random variables, \(X\) and \(Y\) are independent if for any two sets \(A\) and \(B\) \[P([X \in A] \cap [Y \in B]) = P(X\in A)P(Y\in B)\]</li>
<li><p>If \(A\) is independent of \(B\) then </p>

<ul>
<li>\(A^c\) is independent of \(B\) </li>
<li>\(A\) is independent of \(B^c\)</li>
<li>\(A^c\) is independent of \(B^c\)</li>
</ul></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-2" style="background:;">
  <hgroup>
    <h2>Example</h2>
  </hgroup>
  <article>
    <ul>
<li>What is the probability of getting two consecutive heads?</li>
<li>\(A = \{\mbox{Head on flip 1}\}\) ~ \(P(A) = .5\)</li>
<li>\(B = \{\mbox{Head on flip 2}\}\) ~ \(P(B) = .5\)</li>
<li>\(A \cap B = \{\mbox{Head on flips 1 and 2}\}\)</li>
<li>\(P(A \cap B) = P(A)P(B) = .5 \times .5 = .25\) </li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-3" style="background:;">
  <hgroup>
    <h2>Example</h2>
  </hgroup>
  <article>
    <ul>
<li>Volume 309 of Science reports on a physician who was on trial for expert testimony in a criminal trial</li>
<li>Based on an estimated prevalence of sudden infant death syndrome of \(1\) out of \(8,543\), Dr Meadow testified that that the probability of a mother having two children with SIDS was \(\left(\frac{1}{8,543}\right)^2\)</li>
<li>The mother on trial was convicted of murder</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-4" style="background:;">
  <hgroup>
    <h2>Example: continued</h2>
  </hgroup>
  <article>
    <ul>
<li>For the purposes of this class, the principal mistake was to <em>assume</em> that the probabilities of having SIDs within a family are independent</li>
<li>That is, \(P(A_1 \cap A_2)\) is not necessarily equal to \(P(A_1)P(A_2)\)</li>
<li>Biological processes that have a believed genetic or familiar environmental component, of course, tend to be dependent within families</li>
<li>(There are many other statistical points of discussion for this case.)</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-5" style="background:;">
  <hgroup>
    <h2>Useful fact</h2>
  </hgroup>
  <article>
    <p>We will use the following fact extensively in this class:</p>

<p><em>If a collection of random variables \(X_1, X_2, \ldots, X_n\) are independent, then their joint distribution is the product of their individual densities or mass functions</em></p>

<p><em>That is, if \(f_i\) is the density for random variable \(X_i\) we have that</em>
\[
f(x_1,\ldots, x_n) = \prod_{i=1}^n f_i(x_i)
\]</p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-6" style="background:;">
  <hgroup>
    <h2>IID random variables</h2>
  </hgroup>
  <article>
    <ul>
<li>Random variables are said to be iid if they are independent and identically distributed</li>
<li>iid random variables are the default model for random samples</li>
<li>Many of the important theories of statistics are founded on assuming that variables are iid</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-7" style="background:;">
  <hgroup>
    <h2>Example</h2>
  </hgroup>
  <article>
    <ul>
<li>Suppose that we flip a biased coin with success probability \(p\) \(n\) times, what is the join density of the collection of outcomes?</li>
<li>These random variables are iid with densities \(p^{x_i} (1 - p)^{1-x_i}\) </li>
<li>Therefore
\[
f(x_1,\ldots,x_n) = \prod_{i=1}^n p^{x_i} (1 - p)^{1-x_i} = p^{\sum x_i} (1 - p)^{n - \sum x_i}
\]</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-8" style="background:;">
  <hgroup>
    <h2>Correlation</h2>
  </hgroup>
  <article>
    <ul>
<li>The <strong>covariance</strong> between two random variables \(X\) and \(Y\) is defined as 
\[
Cov(X, Y) = E[(X - \mu_x)(Y - \mu_y)] = E[X Y] - E[X]E[Y]
\]</li>
<li>The following are useful facts about covariance

<ol>
<li>\(Cov(X, Y) = Cov(Y, X)\)</li>
<li>\(Cov(X, Y)\) can be negative or positive</li>
<li>\(|Cov(X, Y)| \leq \sqrt{Var(X) Var(y)}\)</li>
</ol></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-9" style="background:;">
  <hgroup>
    <h2>Correlation</h2>
  </hgroup>
  <article>
    <ul>
<li>The <strong>correlation</strong> between \(X\) and \(Y\) is 
\[
Cor(X, Y) = Cov(X, Y) / \sqrt{Var(X) Var(y)}
\]</li>
</ul>

<ol>
<li>\(-1 \leq Cor(X, Y) \leq 1\)</li>
<li>\(Cor(X, Y) = \pm 1\) if and only if \(X = a + bY\) for some constants \(a\) and \(b\)</li>
<li>\(Cor(X, Y)\) is unitless</li>
<li>\(X\) and \(Y\) are <strong>uncorrelated</strong> if \(Cor(X, Y) = 0\) </li>
<li> \(X\) and \(Y\) are more positively correlated, the closer \(Cor(X,Y)\) is to \(1\)</li>
<li> \(X\) and \(Y\) are more negatively correlated, the closer \(Cor(X,Y)\) is to \(-1\)</li>
</ol>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-10" style="background:;">
  <hgroup>
    <h2>Some useful results</h2>
  </hgroup>
  <article>
    <ul>
<li><p>Let \(\{X_i\}_{i=1}^n\) be a collection of random variables</p>

<ul>
<li>When the \(\{X_i\}\) are uncorrelated \[Var\left(\sum_{i=1}^n a_i X_i + b\right) = \sum_{i=1}^n a_i^2 Var(X_i)\]<br></li>
</ul></li>
<li><p>A commonly used subcase from these properties is that <em>if a collection of random variables \(\{X_i\}\) are uncorrelated</em>, then the variance of the sum is the sum of the variances
\[
Var\left(\sum_{i=1}^n X_i \right) = \sum_{i=1}^n Var(X_i)
\]</p></li>
<li><p>Therefore, it is sums of variances that tend to be useful, not sums of standard deviations; that is, the standard deviation of the sum of bunch of independent random variables is the square root of the sum of the variances, not the sum of the standard deviations</p></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-11" style="background:;">
  <hgroup>
    <h2>The sample mean</h2>
  </hgroup>
  <article>
    <p>Suppose \(X_i\) are iid with variance \(\sigma^2\)</p>

<p>\[
\begin{eqnarray*}
    Var(\bar X) & = & Var \left( \frac{1}{n}\sum_{i=1}^n X_i \right)\\ \\
    & = & \frac{1}{n^2} Var\left(\sum_{i=1}^n X_i \right)\\ \\
    & = & \frac{1}{n^2} \sum_{i=1}^n Var(X_i) \\ \\
    & = & \frac{1}{n^2} \times n\sigma^2 \\ \\
    & = & \frac{\sigma^2}{n}
  \end{eqnarray*}
\]</p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-12" style="background:;">
  <hgroup>
    <h2>Some comments</h2>
  </hgroup>
  <article>
    <ul>
<li>When \(X_i\) are independent with a common variance \(Var(\bar X) = \frac{\sigma^2}{n}\)</li>
<li>\(\sigma/\sqrt{n}\) is called <em>the standard error</em> of the sample mean</li>
<li>The standard error of the sample mean is the standard deviation of the distribution of the sample mean</li>
<li>\(\sigma\) is the standard deviation of the distribution of a single observation</li>
<li>Easy way to remember, the sample mean has to be less variable than a single observation, therefore its standard deviation is divided by a \(\sqrt{n}\)</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-13" style="background:;">
  <hgroup>
    <h2>The sample variance</h2>
  </hgroup>
  <article>
    <ul>
<li>The <strong>sample variance</strong> is defined as 
\[
S^2 =   \frac{\sum_{i=1}^n (X_i - \bar X)^2}{n-1} 
\]</li>
<li>The sample variance is an estimator of \(\sigma^2\)</li>
<li>The numerator has a version that&#39;s quicker for calculation
\[
\sum_{i=1}^n (X_i - \bar X)^2 = \sum_{i=1}^n X_i^2 - n \bar X^2
\]</li>
<li>The sample variance is (nearly) the mean of the squared deviations from the mean</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-14" style="background:;">
  <hgroup>
    <h2>The sample variance is unbiased</h2>
  </hgroup>
  <article>
    <p>\[
  \begin{eqnarray*}
    E\left[\sum_{i=1}^n (X_i - \bar X)^2\right] & = & \sum_{i=1}^n E\left[X_i^2\right] - n E\left[\bar X^2\right] \\ \\
    & = & \sum_{i=1}^n \left\{Var(X_i) + \mu^2\right\} - n \left\{Var(\bar X) + \mu^2\right\} \\ \\
    & = & \sum_{i=1}^n \left\{\sigma^2 + \mu^2\right\} - n \left\{\sigma^2 / n + \mu^2\right\} \\ \\
    & = & n \sigma^2 + n \mu ^ 2 - \sigma^2 - n \mu^2 \\ \\
    & = & (n - 1) \sigma^2
  \end{eqnarray*}
\]</p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-15" style="background:;">
  <hgroup>
    <h2>Hoping to avoid some confusion</h2>
  </hgroup>
  <article>
    <ul>
<li>Suppose \(X_i\) are iid with mean \(\mu\) and variance \(\sigma^2\)</li>
<li>\(S^2\) estimates \(\sigma^2\)</li>
<li>The calculation of \(S^2\) involves dividing by \(n-1\)</li>
<li>\(S / \sqrt{n}\) estimates \(\sigma / \sqrt{n}\) the standard error of the mean</li>
<li>\(S / \sqrt{n}\) is called the sample standard error (of the mean)</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-16" style="background:;">
  <hgroup>
    <h2>Example</h2>
  </hgroup>
  <article>
    <pre><code class="r">data(father.son)
hist(father.son$sheight, col = &quot;lightblue&quot;, border = &quot;black&quot;)
x &lt;- father.son$sheight
n &lt;- length(x)
c(sum((x - mean(x))^2)/(n - 1), var(x), var(x)/n, sd(x), sd(x)/sqrt(n))
</code></pre>

<pre><code>## [1] 7.922545 7.922545 0.007349 2.814702 0.085728
</code></pre>

  </article>
  <!-- Presenter Notes -->
</slide>

    <slide class="backdrop"></slide>
  </slides>

  <!--[if IE]>
    <script 
      src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js">  
    </script>
    <script>CFInstall.check({mode: 'overlay'});</script>
  <![endif]-->
</body>
<!-- Grab CDN jQuery, fall back to local if offline -->
<script src="http://ajax.aspnetcdn.com/ajax/jQuery/jquery-1.7.min.js"></script>
<script>window.jQuery || document.write('<script src="../../libraries/widgets/quiz/js/jquery-1.7.min.js"><\/script>')</script>
<!-- Load Javascripts for Widgets -->
<!-- MathJax: Fall back to local if CDN offline but local image fonts are not supported (saves >100MB) -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<!-- <script src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script> -->
<script>window.MathJax || document.write('<script type="text/x-mathjax-config">MathJax.Hub.Config({"HTML-CSS":{imageFont:null}});<\/script><script src="../../libraries/widgets/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"><\/script>')
</script>
<!-- LOAD HIGHLIGHTER JS FILES -->
<script src="../../libraries/highlighters/highlight.js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<!-- DONE LOADING HIGHLIGHTER JS FILES -->
</html>